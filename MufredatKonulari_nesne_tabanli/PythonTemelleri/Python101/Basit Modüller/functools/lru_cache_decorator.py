# -------------------------------------------------------
# âœ… Python: functools.lru_cache Decorator â€“ Derinlemesine AÃ§Ä±klama
# -------------------------------------------------------

from functools import lru_cache

# ğŸ”· @lru_cache
# -------------------------------------------
# lru_cache (Least Recently Used cache), Python'da recursive veya tekrar eden fonksiyonlarda
# aynÄ± argÃ¼manlarla yapÄ±lan Ã§aÄŸrÄ±larÄ±n sonucunu bir "cache" bellekte tutarak performansÄ± artÄ±ran,
# yerleÅŸik (built-in) bir cache mekanizmasÄ± saÄŸlayan decorator'dur.

# ğŸ” KullanÄ±m SÃ¶z Dizimi:
# @lru_cache(maxsize=128)
# def my_func(x):
#     ...

# âš™ï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r?
# -------------------------------------------
# 1ï¸âƒ£ Fonksiyon her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda, verilen argÃ¼manlara gÃ¶re bir "anahtar" (hash) oluÅŸturur.
# 2ï¸âƒ£ EÄŸer bu anahtar daha Ã¶nce hesaplanmÄ±ÅŸsa, **Ã¶nceden hesaplanan deÄŸer cache'den dÃ¶ner**.
# 3ï¸âƒ£ EÄŸer bu anahtar yoksa, fonksiyon hesaplanÄ±r, sonucu cache'e kaydedilir.
# 4ï¸âƒ£ Cache dolmuÅŸsa â†’ En az kullanÄ±lan (LRU) Ã¶ÄŸe silinir, yeni Ã¶ÄŸe eklenir.

# ğŸ’¡ Performans FarkÄ±:
# Normal recursive fonksiyonlarda, alt fonksiyon Ã§aÄŸrÄ±larÄ± **tekrar tekrar hesaplanÄ±r**.
# lru_cache, her alt problemi **sadece bir kez Ã§Ã¶zer**. Ã–zellikle Fibonacci gibi problemler iÃ§in 1000 kat hÄ±z kazandÄ±rÄ±r.

# ğŸ§ª Parametre: maxsize
# -------------------------------------------
# â¤ maxsize â†’ Cache belleÄŸinde tutulacak maksimum farklÄ± sonucu belirler.
# â¤ EÄŸer maxsize=None verilirse â†’ cache boyutu sÄ±nÄ±rsÄ±z olur, hiÃ§bir sonuÃ§ silinmez.
# â¤ EÄŸer maxsize=128 verilirse ve 129. farklÄ± giriÅŸ yapÄ±lÄ±rsa:
#     ğŸ”„ En az kullanÄ±lan (en eski) giriÅŸ silinir, yeni deÄŸer eklenir.

# â• maxsize deÄŸeri belirtilebilir:
#    - YÃ¼ksek deÄŸer: Daha Ã§ok cache, daha az tekrar hesaplama, ama daha Ã§ok bellek
#    - DÃ¼ÅŸÃ¼k deÄŸer: Az bellek, ama sÄ±k cache temizleme
#    - UygulamanÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne gÃ¶re belirlenmelidir

# ğŸ” Recursive Fonksiyonlar iÃ§in:
# -------------------------------------------
# Recursive yapÄ±lar Ã§ok fazla alt fonksiyon Ã§aÄŸrÄ±sÄ± yapar. Ã–rneÄŸin fib(100):
#    - fib(99), fib(98), fib(97)... gibi onlarca kez aynÄ± alt fonksiyonlar Ã§aÄŸrÄ±lÄ±r
#    - lru_cache bu tekrarlarÄ± ortadan kaldÄ±rarak hesaplamayÄ± lineer hale getirir

# .cache_info() metodu, cache'in istatistiksel bilgilerini verir.
# DÃ¶nen deÄŸer bir namedtuple'dÄ±r: CacheInfo(hits, misses, maxsize, currsize)
# hits     â†’ Cache'e denk gelen, hesaplamadan dÃ¶nen Ã§aÄŸrÄ± sayÄ±sÄ±
# misses   â†’ Cache'te bulunamayan, hesaplanmak zorunda kalan Ã§aÄŸrÄ±lar
# maxsize  â†’ LRU cache'in tanÄ±mlanan maksimum kapasitesi
# currsize â†’ Åu anda kaÃ§ farklÄ± argÃ¼man kombinasyonu cache'de tutuluyor

# .cache_clear() metodu, cache belleÄŸini tamamen sÄ±fÄ±rlar.
# TÃ¼m Ã¶nceden saklanmÄ±ÅŸ sonuÃ§lar unutulur.
# Genellikle testlerde, Ã¶lÃ§Ã¼mlerde ya da runtime'da yeni hesaplama zorlandÄ±ÄŸÄ±nda kullanÄ±lÄ±r.


# --------------------------------------------------
# âœ… @lru_cache KullanÄ±m AlanlarÄ±
# --------------------------------------------------

# 1. ğŸ” Recursive Fonksiyonlar
# --------------------------------------------------
# Fibonacci, DFS, n! gibi tekrar eden alt Ã§aÄŸrÄ±lar iÃ§eren yapÄ±lar.
# AynÄ± alt problemi defalarca Ã§Ã¶zmek yerine, sonucu saklar ve doÄŸrudan dÃ¶ndÃ¼rÃ¼r.

# 2. ğŸ“¡ API Ä°stekleri
# --------------------------------------------------
# AynÄ± endpoint'e aynÄ± argÃ¼manlarla tekrar istek yapÄ±lacaksa,
# sonucu cache'e koyar â†’ 2. kez aynÄ± URL Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda anÄ±nda yanÄ±t dÃ¶ner.

# 3. ğŸ§® Hesaplama Maliyetli Fonksiyonlar
# --------------------------------------------------
# BÃ¼yÃ¼k matris iÅŸlemleri, istatistiksel analiz, graf hesaplamalarÄ±.
# Ã–zellikle input sabitse sonucu cache'lemek Ã§ok kazanÃ§ saÄŸlar.

# 4. ğŸ” Veri SorgularÄ±
# --------------------------------------------------
# AynÄ± SQL query'lerini tekrar tekrar Ã§alÄ±ÅŸtÄ±rmak yerine,
# ilk sorguyu cache'e alÄ±r, sonraki Ã§aÄŸrÄ±lar iÃ§in cache'den getirir.

# 5. ğŸ§¾ Config/Ayar Okuma
# --------------------------------------------------
# Dosyadan okunan ayarlar, sabit yapÄ±daki veriler tekrar tekrar yÃ¼klenmek yerine cache'ten alÄ±nabilir.

# 6. ğŸ“‚ Dosya Parsing
# --------------------------------------------------
# Ã–zellikle bÃ¼yÃ¼k JSON/XML dosyalarÄ± tekrar iÅŸlenmek yerine parse edilmiÅŸ versiyonlarÄ± saklanabilir.

# 7. ğŸ§  NLP, AI & ML Ã¶n hesaplamalar
# --------------------------------------------------
# Tokenizasyon, Ã¶n iÅŸlem, vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼m gibi adÄ±mlar cache ile hÄ±zlandÄ±rÄ±labilir.

# --------------------------------------------------
# âš ï¸ KullanÄ±lmamasÄ± Gereken Durumlar:
# --------------------------------------------------
# 1. Fonksiyon Ã§Ä±ktÄ±sÄ± deÄŸiÅŸkense (Ã¶rn: zaman, rastgelelik iÃ§eriyorsa)
# 2. Fonksiyon yan etki yapÄ±yorsa (Ã¶rn: dosya yazÄ±yor, DB deÄŸiÅŸtiriyor)
# 3. BÃ¼yÃ¼k veri dÃ¶ndÃ¼rÃ¼yorsa (RAM ÅŸiÅŸebilir)


from functools import lru_cache



# -----------------------------------------------
# ğŸ” lru_cache(typed=True) AÃ§Ä±klamasÄ±
# -----------------------------------------------

# @lru_cache, fonksiyonun sonuÃ§larÄ±nÄ± "girdi -> Ã§Ä±ktÄ±" ÅŸeklinde cache (Ã¶nbellek) yapan bir decorator'dÃ¼r.
# typed parametresi, bu eÅŸlemede fonksiyon argÃ¼manlarÄ±nÄ±n sadece deÄŸerine deÄŸil,
# veri tipine gÃ¶re de ayÄ±rt edilip edilmediÄŸini kontrol eder.

# ğŸ”¸ typed=False (varsayÄ±lan)
# - ArgÃ¼manlar sadece deÄŸere gÃ¶re karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
# - f(1) ve f(1.0) aynÄ± kabul edilir â†’ cache ortak olur.

# ğŸ”¸ typed=True
# - ArgÃ¼manlarÄ±n tipleri de anahtarÄ±n parÃ§asÄ± olur.
# - f(1) â‰  f(1.0) â†’ ayrÄ± ayrÄ± cache anahtarlarÄ±

# Bu ayar, tip duyarlÄ± hesaplamalarda doÄŸruluk aÃ§Ä±sÄ±ndan Ã§ok Ã¶nemlidir.

# -----------------------------------------------
# Ã–rnek Fonksiyon
# -----------------------------------------------

@lru_cache(typed=True)  # ğŸ”§ Tip duyarlÄ±lÄ±ÄŸÄ± aktif
def process(value):
    print(f"â†’ HesaplandÄ±: {value!r} (type: {type(value).__name__})")
    return value

# -----------------------------------------------
# ğŸ§ª Ã‡aÄŸrÄ±lar
# -----------------------------------------------

process(5)      # ğŸŸ¡ Ä°lk kez: hesaplanÄ±r ve cache'e eklenir
process(5)      # âœ… Cache HIT: tekrar hesaplanmaz
process(5.0)    # ğŸŸ¡ Yeni tip (float): farklÄ± anahtar â†’ hesaplanÄ±r
process(5.0)    # âœ… Cache HIT

# EÄŸer typed=False olsaydÄ±:
# process(5) ve process(5.0) aynÄ± kabul edilir, sadece ilk Ã§aÄŸrÄ± hesaplanÄ±rdÄ±

# -----------------------------------------------
# Ne Zaman typed=True KullanÄ±lÄ±r?
# -----------------------------------------------

# âœ”ï¸ EÄŸer fonksiyonun Ã§Ä±ktÄ±sÄ± argÃ¼manÄ±n sadece deÄŸeri deÄŸil, veri tipiyle de deÄŸiÅŸiyorsa:
#    â†’ typed=True kullanmak gerekir

# âŒ EÄŸer Ã§Ä±ktÄ±, tipi fark etmiyorsa:
#    â†’ typed=False (varsayÄ±lan) tercih edilebilir â†’ daha az bellek

# -----------------------------------------------
# Ã–rnek SonuÃ§lar:
#
# â†’ HesaplandÄ±: 5 (type: int)
# â†’ HesaplandÄ±: 5.0 (type: float)
#
# â†’ Sonraki aynÄ± Ã§aÄŸrÄ±lar cache'den dÃ¶ner
# -----------------------------------------------


# ğŸ§  Uygulama Ã–rneÄŸi:

import time

@lru_cache(maxsize=3)
def fib(n):
    if n < 2:
        return n
    return fib(n-1) + fib(n-2)

start = time.perf_counter()
print(fib(50))
end = time.perf_counter()
print(f"SÃ¼re: {end - start:.4f} sn")

print(fib.cache_info()) # CacheInfo(hits=198, misses=201, maxsize=3, currsize=3)

# hits = 198
# -------------------------------------------
# Cache'e denk gelen baÅŸarÄ±lÄ± sorgu sayÄ±sÄ±dÄ±r.
# Yani fonksiyon Ã§aÄŸrÄ±sÄ± Ã¶nceden cache'e kaydedilmiÅŸti, tekrar hesaplama yapÄ±lmadÄ±.
# Bu durumda direkt olarak cache'deki deÄŸer kullanÄ±ldÄ±.
# YÃ¼ksek hit oranÄ± = verimli cache kullanÄ±mÄ± demektir.

# misses = 201
# -------------------------------------------
# Cache'te bulunamayan, yani hesaplanmak zorunda kalan Ã§aÄŸrÄ± sayÄ±sÄ±dÄ±r.
# Fonksiyon Ã§aÄŸrÄ±sÄ± daha Ã¶nce yapÄ±lmamÄ±ÅŸ â†’ cache'te yoktu â†’ hesaplandÄ± ve cache'e eklendi.
# YÃ¼ksek miss oranÄ± â†’ ya cache yeni baÅŸlÄ±yor, ya da maxsize Ã§ok kÃ¼Ã§Ã¼k!

# maxsize = 3
# -------------------------------------------
# Cache'te aynÄ± anda tutulabilecek maksimum farklÄ± fonksiyon sonucu sayÄ±sÄ±dÄ±r.
# maxsize=3 demek â†’ cache, en fazla 3 farklÄ± girdi iÃ§in sonucu saklar.
# Yeni bir girdi geldiÄŸinde â†’ en az kullanÄ±lan (LRU) silinir.

# currsize = 3
# -------------------------------------------
# Åu anda cache'te tutulan farklÄ± sonucu sayÄ±sÄ±dÄ±r.
# Genellikle maxsizeâ€™a ulaÅŸÄ±r â†’ ve orada sabit kalÄ±r.

@lru_cache(maxsize=None)
def file_extension(filename: str) -> str:
    return filename.split('.')[-1].lower()

print(file_extension("test.txt"))


@lru_cache()
def planet_gravity(planet: str) -> float:
    planets = {"earh":9.81, "mars":3.7}
    return planets.setdefault(planet,None)

print(planet_gravity("earh"))
print(planet_gravity("mars"))


def give_key(typed: bool,*args, **kwargs):
    if typed:
        _args = tuple(map(normalize_type,args))
        _kwargs = {k:normalize_type(v) for k,v in kwargs.items()}
        return hash((_args, frozenset(_kwargs.items())))
    return hash((args, frozenset(kwargs.items())))

def normalize_type(x):
    if isinstance(x,float) and x.is_integer():
        return int(x)
    elif isinstance(x,bool):
        return int(x)
    return x

class Mylru_cache:

    def __init__(self,*,maxsize=None, typed= False):
        self.__maxsize = maxsize
        self.__typed = typed
        self.__cache = {}

    def __call__(self, func):
        self.__func = func
        def wrapper(*args,**kwargs):
            key = give_key(self.__typed,*args,**kwargs)
            if key not in self.__cache:
                self.__cache[key] =  func(*args,**kwargs)
                return self.__cache[key]
            return self.__cache[key]

        return wrapper

@Mylru_cache()
def fib(n):
    if n < 2:
        return n
    return fib(n-1) + fib(n-2)

print(fib(50))
